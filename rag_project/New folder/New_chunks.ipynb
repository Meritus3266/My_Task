{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2ec54ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " All imports successful\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from typing import Literal\n",
    "import os\n",
    "import pypdf\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "print(\" All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40e6d14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " API key loaded\n"
     ]
    }
   ],
   "source": [
    "# Load API key\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found! Please set it in your .env file.\")\n",
    "\n",
    "print(\" API key loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "333e6692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LLM initialized: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.5,\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "print(f\" LLM initialized: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08a96613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 90 pages from LAW 243.pdf\n",
      " Loaded 135 pages from law 432 LAW OF BANKING AND INSURANCE II  post editorial.pdf\n",
      " Loaded 194 pages from LAW411 oil and gas I.pdf\n",
      "\n",
      " Total pages loaded: 419\n"
     ]
    }
   ],
   "source": [
    "# Define the folder containing PDF files\n",
    "pdf_folder = \".\"  # Current folder where the PDFs are located\n",
    "pdf_files = [\n",
    "    \"LAW 243.pdf\",\n",
    "    \"law 432 LAW OF BANKING AND INSURANCE II  post editorial.pdf\",\n",
    "    \"LAW411 oil and gas I.pdf\"\n",
    "]\n",
    "\n",
    "pages = []\n",
    "\n",
    "# Load all PDF files\n",
    "for pdf_file in pdf_files:\n",
    "    file_path = os.path.join(pdf_folder, pdf_file)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\" File not found: {file_path}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Load the PDF\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        pdf_pages = loader.load()\n",
    "        pages.extend(pdf_pages)\n",
    "        print(f\" Loaded {len(pdf_pages)} pages from {pdf_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error loading {pdf_file}: {str(e)}\")\n",
    "\n",
    "print(f\"\\n Total pages loaded: {len(pages)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3259d471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Created 942 chunks from 419 pages\n",
      " Chunk statistics:\n",
      "   - Average chunk size: 768 characters\n",
      "   - Min chunk size: 2 characters\n",
      "   - Max chunk size: 999 characters\n",
      "\n",
      " Sample chunk (Chunk 1):\n",
      "   Source: .\\LAW 243.pdf\n",
      "   Page: 0\n",
      "   Length: 32 characters\n",
      "\n",
      "   Content preview:\n",
      "   LAW 243    \n",
      "CONSTITUTIONAL LAW 1...\n"
     ]
    }
   ],
   "source": [
    "# Verify pages were loaded\n",
    "if not pages:\n",
    "    raise ValueError(\"No pages loaded! Please check your PDF files.\")\n",
    "\n",
    "# Create text splitter (Module 2 knowledge!)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # Characters per chunk\n",
    "    chunk_overlap=100,    # Overlap to preserve context\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Split documents\n",
    "doc_splits = text_splitter.split_documents(pages)\n",
    "\n",
    "print(f\" Created {len(doc_splits)} chunks from {len(pages)} pages\")\n",
    "print(f\" Chunk statistics:\")\n",
    "print(f\"   - Average chunk size: {sum(len(chunk.page_content) for chunk in doc_splits) // len(doc_splits)} characters\")\n",
    "print(f\"   - Min chunk size: {min(len(chunk.page_content) for chunk in doc_splits)} characters\")\n",
    "print(f\"   - Max chunk size: {max(len(chunk.page_content) for chunk in doc_splits)} characters\")\n",
    "\n",
    "# Display sample chunk with metadata\n",
    "if doc_splits:\n",
    "    print(f\"\\n Sample chunk (Chunk 1):\")\n",
    "    print(f\"   Source: {doc_splits[0].metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"   Page: {doc_splits[0].metadata.get('page', 'Unknown')}\")\n",
    "    print(f\"   Length: {len(doc_splits[0].page_content)} characters\")\n",
    "    print(f\"\\n   Content preview:\")\n",
    "    print(f\"   {doc_splits[0].page_content[:300]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "560104d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chunks Distribution by Document:\n",
      "\n",
      "================================================================================\n",
      "\n",
      " LAW 243.pdf\n",
      "   ├─ Total chunks: 231\n",
      "   ├─ Total characters: 186,690\n",
      "   └─ Average chunk size: 808 characters\n",
      "\n",
      " law 432 LAW OF BANKING AND INSURANCE II  post editorial.pdf\n",
      "   ├─ Total chunks: 229\n",
      "   ├─ Total characters: 169,632\n",
      "   └─ Average chunk size: 740 characters\n",
      "\n",
      " LAW411 oil and gas I.pdf\n",
      "   ├─ Total chunks: 482\n",
      "   ├─ Total characters: 367,694\n",
      "   └─ Average chunk size: 762 characters\n",
      "\n",
      "================================================================================\n",
      " Total: 942 chunks from 3 documents\n"
     ]
    }
   ],
   "source": [
    "# Analyze chunks by document source\n",
    "from collections import defaultdict\n",
    "\n",
    "chunks_by_source = defaultdict(list)\n",
    "\n",
    "for chunk in doc_splits:\n",
    "    source = chunk.metadata.get('source', 'Unknown')\n",
    "    chunks_by_source[source].append(chunk)\n",
    "\n",
    "print(\" Chunks Distribution by Document:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for source, chunks in chunks_by_source.items():\n",
    "    total_chars = sum(len(chunk.page_content) for chunk in chunks)\n",
    "    avg_chars = total_chars // len(chunks) if chunks else 0\n",
    "    \n",
    "    # Extract filename from full path\n",
    "    filename = source.split(\"\\\\\")[-1] if \"\\\\\" in source else source.split(\"/\")[-1] if \"/\" in source else source\n",
    "    \n",
    "    print(f\"\\n {filename}\")\n",
    "    print(f\"   ├─ Total chunks: {len(chunks)}\")\n",
    "    print(f\"   ├─ Total characters: {total_chars:,}\")\n",
    "    print(f\"   └─ Average chunk size: {avg_chars:,} characters\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\" Total: {len(doc_splits)} chunks from {len(chunks_by_source)} documents\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a868d55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Initializing embeddings and creating vector database...\n",
      " Vector store created with 942 chunks\n",
      " Persistent storage: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "# Initialize embeddings and create vector store\n",
    "print(\" Initializing embeddings and creating vector database...\")\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "# Create Chroma vector store\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "print(f\" Vector store created with {len(doc_splits)} chunks\")\n",
    "print(f\" Persistent storage: ./chroma_db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18704e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retriever tool created successfully\n"
     ]
    }
   ],
   "source": [
    "# Define retriever tool for the agent\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "@tool\n",
    "def search_documents(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the policy documents for relevant information.\n",
    "    Use this tool to find answers about the legal documents.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        docs = retriever.invoke(query)\n",
    "        \n",
    "        if not docs:\n",
    "            return \"No relevant documents found for this query.\"\n",
    "        \n",
    "        # Format retrieved documents with sources\n",
    "        results = []\n",
    "        for i, doc in enumerate(docs, 1):\n",
    "            source = doc.metadata.get('source', 'Unknown')\n",
    "            page = doc.metadata.get('page', 'N/A')\n",
    "            filename = source.split(\"\\\\\")[-1] if \"\\\\\" in source else source.split(\"/\")[-1] if \"/\" in source else source\n",
    "            \n",
    "            results.append(f\"[Source {i}: {filename} (Page {page})]\\n{doc.page_content}\\n\")\n",
    "        \n",
    "        return \"\\n---\\n\".join(results)\n",
    "    except Exception as e:\n",
    "        return f\"Error searching documents: {str(e)}\"\n",
    "\n",
    "print(\" Retriever tool created successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0276bebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Agentic RAG system initialized successfully\n",
      " System components:\n",
      "   ├─ LLM: gpt-4o-mini\n",
      "   ├─ Embeddings: text-embedding-3-small\n",
      "   ├─ Vector Store: Chroma with 3 documents\n",
      "   ├─ Retriever: Semantic search (k=3)\n",
      "   └─ Agent: ReAct agent with conversation memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ncc333\\AppData\\Local\\Temp\\ipykernel_2592\\1936763313.py:8: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent_executor = create_react_agent(llm, tools)\n"
     ]
    }
   ],
   "source": [
    "# Build the agentic RAG system with LangGraph\n",
    "\n",
    "\n",
    "# Define tools\n",
    "tools = [search_documents]\n",
    "\n",
    "# Create the agent\n",
    "agent_executor = create_react_agent(llm, tools)\n",
    "\n",
    "# Create a state graph for conversation management\n",
    "class AgentState(MessagesState):\n",
    "    \"\"\"State for managing conversation context\"\"\"\n",
    "    pass\n",
    "\n",
    "def agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Process user query and generate response with document retrieval\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Add system prompt for document-aware responses\n",
    "    system_prompt = SystemMessage(\n",
    "        content=\"\"\"You are an intelligent policy assistant. Your role is to answer questions about policy documents \n",
    "        with accuracy and helpfulness. \n",
    "\n",
    "IMPORTANT INSTRUCTIONS:\n",
    "1. Always use the search_documents tool to find relevant information\n",
    "2. Provide sources for every piece of information you cite\n",
    "3. Format citations clearly: [Source: Document Name (Page X)]\n",
    "4. If you cannot find relevant information, be honest about it\n",
    "5. Maintain conversation context and refer to previous messages when relevant\n",
    "6. Be concise but thorough in your answers\"\"\"\n",
    "    )\n",
    "    \n",
    "    # Prepare messages with system context\n",
    "    messages_with_system = [system_prompt] + messages\n",
    "    \n",
    "    # Call the agent\n",
    "    response = agent_executor.invoke({\"messages\": messages_with_system})\n",
    "    \n",
    "    # Extract the final response\n",
    "    final_message = response[\"messages\"][-1]\n",
    "    \n",
    "    return AgentState(messages=state[\"messages\"] + [final_message])\n",
    "\n",
    "# Create the graph\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"agent\", agent_node)\n",
    "\n",
    "# Set START -> agent -> END\n",
    "graph.add_edge(START, \"agent\")\n",
    "graph.add_edge(\"agent\", END)\n",
    "\n",
    "# Compile with memory\n",
    "memory = MemorySaver()\n",
    "compiled_agent = graph.compile(checkpointer=memory)\n",
    "\n",
    "print(\" Agentic RAG system initialized successfully\")\n",
    "print(\" System components:\")\n",
    "print(\"   ├─ LLM: gpt-4o-mini\")\n",
    "print(\"   ├─ Embeddings: text-embedding-3-small\")\n",
    "print(\"   ├─ Vector Store: Chroma with 3 documents\")\n",
    "print(\"   ├─ Retriever: Semantic search (k=3)\")\n",
    "print(\"   └─ Agent: ReAct agent with conversation memory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d66943ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select mode:\n",
      "1. Interactive Chat (type your questions)\n",
      "2. Run Test Queries\n",
      "Invalid choice. Running interactive chat by default...\n",
      "\n",
      "================================================================================\n",
      " Welcome to the Agentic RAG System\n",
      "================================================================================\n",
      "\n",
      "Commands:\n",
      "  - Type your question to query the system\n",
      "  - Type 'new' to start a new conversation session\n",
      "  - Type 'quit' or 'exit' to end the session\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      " User Query: what is constitutional law\n",
      "================================================================================\n",
      "\n",
      " Assistant Response:\n",
      "Constitutional law is a body of law that defines the structure and function of government institutions, as well as the rights of individuals in relation to the state. It encompasses the interpretation and implementation of a country's constitution, which serves as the supreme legal authority. Key aspects of constitutional law include:\n",
      "\n",
      "1. **Fundamental Rights**: Protecting individual rights and liberties against government infringement.\n",
      "2. **Separation of Powers**: Dividing government responsibilities among different branches (executive, legislative, and judicial) to prevent abuse of power.\n",
      "3. **Checks and Balances**: Ensuring that each branch of government can limit the powers of the others, maintaining a balance of power.\n",
      "4. **Judicial Review**: Allowing courts to assess the constitutionality of legislative and executive actions.\n",
      "\n",
      "Constitutional law varies by country, reflecting each nation's unique legal framework and historical context. If you have a specific aspect of constitutional law you would like to explore further, please let me know!\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Thank you for using the Agentic RAG System. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# # Test the agent with sample queries\n",
    "# def run_query(user_query: str, session_id: str = \"default\"):\n",
    "#     \"\"\"Run a query through the agentic RAG system\"\"\"\n",
    "#     print(f\"\\n{'='*80}\")\n",
    "#     print(f\" User Query: {user_query}\")\n",
    "#     print(f\"{'='*80}\")\n",
    "    \n",
    "#     # Create input state\n",
    "#     input_state = AgentState(messages=[HumanMessage(content=user_query)])\n",
    "    \n",
    "#     # Run the agent with session/thread ID for context management\n",
    "#     result = compiled_agent.invoke(\n",
    "#         input_state,\n",
    "#         config={\"configurable\": {\"thread_id\": session_id}}\n",
    "#     )\n",
    "    \n",
    "#     # Extract and display the response\n",
    "#     response = result[\"messages\"][-1]\n",
    "#     print(f\"\\n Assistant Response:\")\n",
    "#     print(f\"{response.content}\")\n",
    "#     print(f\"{'='*80}\\n\")\n",
    "    \n",
    "#     return response.content\n",
    "\n",
    "# # Test queries\n",
    "# print(\" Testing Agentic RAG System\\n\")\n",
    "\n",
    "# # Test 1: Initial query\n",
    "# response1 = run_query(\"What is LAW 243 about?\", session_id=\"session_1\")\n",
    "\n",
    "# # Test 2: Follow-up question (tests context management)\n",
    "# response2 = run_query(\"Can you provide more details about the main topics?\", session_id=\"session_1\")\n",
    "\n",
    "# # Test 3: Different document\n",
    "# response3 = run_query(\"What are the key provisions in LAW411 about oil and gas?\", session_id=\"session_2\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_query(user_query: str, session_id: str = \"default\"):\n",
    "    \"\"\"Run a query through the agentic RAG system\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\" User Query: {user_query}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Create input state\n",
    "    input_state = AgentState(messages=[HumanMessage(content=user_query)])\n",
    "    \n",
    "    # Run the agent with session/thread ID for context management\n",
    "    result = compiled_agent.invoke(\n",
    "        input_state,\n",
    "        config={\"configurable\": {\"thread_id\": session_id}}\n",
    "    )\n",
    "    \n",
    "    # Extract and display the response\n",
    "    response = result[\"messages\"][-1]\n",
    "    print(f\"\\n Assistant Response:\")\n",
    "    print(f\"{response.content}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return response.content\n",
    "\n",
    "def interactive_chat():\n",
    "    \"\"\"Interactive chat interface for the agentic RAG system\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" Welcome to the Agentic RAG System\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nCommands:\")\n",
    "    print(\"  - Type your question to query the system\")\n",
    "    print(\"  - Type 'new' to start a new conversation session\")\n",
    "    print(\"  - Type 'quit' or 'exit' to end the session\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    session_id = \"session_1\"\n",
    "    session_counter = 1\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # Get user input\n",
    "            user_input = input(\"You: \").strip()\n",
    "            \n",
    "            # Check for exit commands\n",
    "            if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "                print(\"\\nThank you for using the Agentic RAG System. Goodbye!\")\n",
    "                break\n",
    "            \n",
    "            # Check for new session command\n",
    "            if user_input.lower() == 'new':\n",
    "                session_counter += 1\n",
    "                session_id = f\"session_{session_counter}\"\n",
    "                print(f\"\\n Started new conversation session: {session_id}\\n\")\n",
    "                continue\n",
    "            \n",
    "            # Skip empty inputs\n",
    "            if not user_input:\n",
    "                continue\n",
    "            \n",
    "            # Run the query\n",
    "            run_query(user_input, session_id=session_id)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nSession interrupted. Goodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\n Error: {str(e)}\\n\")\n",
    "            continue\n",
    "\n",
    "def run_test_queries():\n",
    "    \"\"\"Run predefined test queries\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" Running Test Queries\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Test 1: Initial query\n",
    "    print(\"TEST 1: Initial query\")\n",
    "    response1 = run_query(\"What is LAW 243 about?\", session_id=\"test_session_1\")\n",
    "    \n",
    "    # Test 2: Follow-up question (tests context management)\n",
    "    print(\"\\nTEST 2: Follow-up question\")\n",
    "    response2 = run_query(\"Can you provide more details about the main topics?\", session_id=\"test_session_1\")\n",
    "    \n",
    "    # Test 3: Different document\n",
    "    print(\"\\nTEST 3: Different document query\")\n",
    "    response3 = run_query(\"What are the key provisions in LAW411 about oil and gas?\", session_id=\"test_session_2\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" Test Queries Completed\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nSelect mode:\")\n",
    "    print(\"1. Interactive Chat (type your questions)\")\n",
    "    print(\"2. Run Test Queries\")\n",
    "    \n",
    "    choice = input(\"\\nEnter your choice (1 or 2): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        interactive_chat()\n",
    "    elif choice == \"2\":\n",
    "        run_test_queries()\n",
    "    else:\n",
    "        print(\"Invalid choice. Running interactive chat by default...\")\n",
    "        interactive_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
