{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4852541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " All imports successful\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "print(\" All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a72e215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found! Please set it in your .env file.\")\n",
    "\n",
    "print(\" API key loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14061f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY present: True\n"
     ]
    }
   ],
   "source": [
    "# Ensure env is reloaded if needed (no additional key checks here)\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"OPENAI_API_KEY present:\", bool(openai_api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29a621b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized: profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True} client=<openai.resources.chat.completions.completions.Completions object at 0x0000026EE3C1B230> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000026EE3C1B5C0> root_client=<openai.OpenAI object at 0x0000026EE3C1A060> root_async_client=<openai.AsyncOpenAI object at 0x0000026EE3C1B360> model_name='gpt-4o-mini' temperature=0.0 model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,  # Lower temperature for more precise tool usage\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "print(f\"LLM initialized: {llm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7057e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " System prompt defined\n"
     ]
    }
   ],
   "source": [
    "# Define the system prompt for customer support\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful and empathetic customer support representative for TechCorp Electronics.\n",
    "\n",
    "Your responsibilities:\n",
    "- Listen carefully to customer issues and concerns\n",
    "- Remember what the customer has told you about their problem\n",
    "- Provide helpful troubleshooting steps\n",
    "- Offer solutions based on the context of the conversation\n",
    "- Be professional but friendly\n",
    "\n",
    "Always:\n",
    "1. Acknowledge the customer's issue with empathy\n",
    "2. Reference previous details from the conversation when relevant\n",
    "3. Ask clarifying questions if needed\n",
    "4. Provide clear, step-by-step solutions\n",
    "5. Offer to escalate if the problem is beyond your scope\n",
    "\n",
    "Remember: You have access to the full conversation history - use it to provide personalized support!\"\"\"\n",
    "\n",
    "print(\" System prompt defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb3a2d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Agent function created\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# Create the agent node function\n",
    "def customer_support_agent(state: MessagesState) -> dict:\n",
    "    \"\"\"\n",
    "    The main agent node that processes messages and maintains context.\n",
    "    \n",
    "    Args:\n",
    "        state: MessagesState containing the conversation history\n",
    "        \n",
    "    Returns:\n",
    "        Updated state with the agent's response added to messages\n",
    "    \"\"\"\n",
    "    # Prepare messages: system prompt first, then conversation history\n",
    "    messages = [SystemMessage(content=SYSTEM_PROMPT)] + state[\"messages\"]\n",
    "    \n",
    "    # Get response from LLM\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    # Return the updated state with the new assistant message\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "print(\" Agent function created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91ab5a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " StateGraph structure created\n"
     ]
    }
   ],
   "source": [
    "# Create the StateGraph\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add the agent node\n",
    "graph_builder.add_node(\"agent\", customer_support_agent)\n",
    "\n",
    "# Add edges to connect START -> agent -> END\n",
    "graph_builder.add_edge(START, \"agent\")\n",
    "graph_builder.add_edge(\"agent\", END)\n",
    "\n",
    "print(\" StateGraph structure created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b57c44a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Graph compiled with MemorySaver checkpointer\n",
      "   Conversation memory is now persistent!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the checkpointer for memory persistence\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer\n",
    "customer_support_graph = graph_builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\" Graph compiled with MemorySaver checkpointer\")\n",
    "print(\"   Conversation memory is now persistent!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "103fcdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Helper function created\n"
     ]
    }
   ],
   "source": [
    "# Helper function to manage conversations\n",
    "def run_support_conversation(user_input: str, thread_id: str = \"support-chat-1\"):\n",
    "    \"\"\"\n",
    "    Run a single turn in the customer support conversation.\n",
    "    \n",
    "    Args:\n",
    "        user_input: The user's message\n",
    "        thread_id: Unique ID for this conversation thread\n",
    "        \n",
    "    Returns:\n",
    "        The agent's response as a string\n",
    "    \"\"\"\n",
    "    # Create the input state with user's message\n",
    "    input_state = {\"messages\": [HumanMessage(content=user_input)]}\n",
    "    \n",
    "    # Invoke the graph with thread_id for memory persistence\n",
    "    output = customer_support_graph.invoke(\n",
    "        input_state,\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "    \n",
    "    # Extract the agent's response\n",
    "    agent_response = output[\"messages\"][-1]\n",
    "    return agent_response.content\n",
    "\n",
    "print(\" Helper function created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "703c1556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " CUSTOMER SUPPORT CHATBOT - INTERACTIVE MODE\n",
      "================================================================================\n",
      "\n",
      "Thread ID: session-5bba2a19\n",
      "Type 'exit' to end the conversation\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Agent (Turn 1): I completely understand your desire for a durable system that will stand the test of time. To help you better, could you please share what specific type of system youâ€™re looking for? Are you interested in a laptop, desktop, gaming system, or perhaps another type of electronic device? Additionally, if you have any particular requirements or budget in mind, that would be helpful too!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Agent (Turn 2): Thank you for clarifying that you're looking for a laptop! For a laptop that lasts longer, here are a few key factors to consider:\n",
      "\n",
      "1. **Build Quality:** Look for laptops with aluminum or magnesium chassis, as they tend to be more durable than plastic ones.\n",
      "\n",
      "2. **Battery Life:** Opt for laptops that offer extended battery life, which can indicate better longevity in terms of usage.\n",
      "\n",
      "3. **Performance Components:** Choose laptops with solid-state drives (SSDs) and sufficient RAM (at least 16GB) to keep the system running smoothly over the years.\n",
      "\n",
      "4. **Warranty and Support:** Consider brands that offer robust customer support and longer warranty periods.\n",
      "\n",
      "Some brands known for their durability include:\n",
      "\n",
      "- **Apple MacBook Pro:** Known for its excellent build quality and long lifespan.\n",
      "- **Dell XPS Series:** Offers premium materials and performance.\n",
      "- **Lenovo ThinkPad Series:** Renowned for its durability and reliability, especially for business use.\n",
      "- **HP EliteBook Series:** Designed for professional use with solid construction.\n",
      "\n",
      "If you have a specific budget or usage scenario (like gaming, graphic design, or general use), I can provide more tailored recommendations. Let me know!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Conversation ended. Thank you for chatting!\n"
     ]
    }
   ],
   "source": [
    "# Interactive Multi-Turn Conversation\n",
    "import uuid\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\" CUSTOMER SUPPORT CHATBOT - INTERACTIVE MODE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create a unique thread for this session\n",
    "thread_id = f\"session-{str(uuid.uuid4())[:8]}\"\n",
    "print(f\"\\nThread ID: {thread_id}\")\n",
    "print(\"Type 'exit' to end the conversation\\n\")\n",
    "print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "turn = 1\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_input = input(f\"ðŸ‘¤ You (Turn {turn}): \").strip()\n",
    "    \n",
    "    # Check for exit command\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"\\n Conversation ended. Thank you for chatting!\")\n",
    "        break\n",
    "    \n",
    "    # Skip empty messages\n",
    "    if not user_input:\n",
    "        print(\" Please enter a message.\\n\")\n",
    "        continue\n",
    "    \n",
    "    # Get agent response\n",
    "    agent_response = run_support_conversation(user_input, thread_id)\n",
    "    print(f\"\\n Agent (Turn {turn}): {agent_response}\\n\")\n",
    "    print(\"-\" * 80 + \"\\n\")\n",
    "    \n",
    "    turn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "157a46c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " CONVERSATION MEMORY VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "Total messages in thread 'session-bb8f10dd': 4\n",
      "\n",
      "[1] HumanMessage | tell me about dell laptop\n",
      "[2] AIMessage    | Could you please specify what type of information you are looking for ...\n",
      "[3] HumanMessage | what system can i buy for that will last longer\n",
      "[4] AIMessage    | I understand that you're looking for a laptop that will have longevity...\n",
      "\n",
      "================================================================================\n",
      " Memory verification complete!\n"
     ]
    }
   ],
   "source": [
    "# Verify the conversation was stored in memory\n",
    "final_conversation_state = customer_support_graph.get_state(\n",
    "    config={\"configurable\": {\"thread_id\": thread_id}}\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" CONVERSATION MEMORY VERIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal messages in thread '{thread_id}': {len(final_conversation_state.values['messages'])}\\n\")\n",
    "\n",
    "for i, message in enumerate(final_conversation_state.values[\"messages\"], 1):\n",
    "    message_type = type(message).__name__\n",
    "    preview = message.content[:70] + \"...\" if len(message.content) > 70 else message.content\n",
    "    print(f\"[{i}] {message_type:12} | {preview}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" Memory verification complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06b8ac66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " THREAD ISOLATION DEMO\n",
      "================================================================================\n",
      "\n",
      "Each customer can have their own conversation thread without interference.\n",
      "\n",
      "Example: Your thread 'session-bb8f10dd' is isolated from any other customer's thread.\n",
      "\n",
      "To start a new conversation with a different customer, simply create a new thread_id!\n",
      "\n",
      "This enables:\n",
      "   Multiple simultaneous customer chats\n",
      "   Conversation history isolation\n",
      "   Production-ready scalability\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Optional: Test thread isolation with a demo\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" THREAD ISOLATION DEMO\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nEach customer can have their own conversation thread without interference.\")\n",
    "print(f\"\\nExample: Your thread '{thread_id}' is isolated from any other customer's thread.\")\n",
    "print(\"\\nTo start a new conversation with a different customer, simply create a new thread_id!\")\n",
    "print(\"\\nThis enables:\")\n",
    "print(\"   Multiple simultaneous customer chats\")\n",
    "print(\"   Conversation history isolation\")\n",
    "print(\"   Production-ready scalability\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
